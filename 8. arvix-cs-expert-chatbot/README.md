# ğŸ¤– CS Expert AI Assistant  
**CS Expert Chatbot powered by an open-source foundation LLM (Llama 3) + Retrieval Augmented Generation (RAG)**  

## Screenshots

![Chat Interface](screenshots/Chat_Interface.png)

![Visualization](screenshots/Visualization1.png)

![Visualization](screenshots/visualization2.png)

![Visualization](screenshots/visualization3.png)

![Paper Search](screenshots/search.png)



### Why youâ€™ll love it ğŸ’œ  

| Feature | What you get |
|---------|--------------|
| **Foundation LLM with built-in CS knowledge** | Runs locally with **Llama 3** (via [Ollama](https://ollama.ai/)) â€“ no keys, no cost |
| **Retrieval-Augmented Generation** | Semantic search over **arXiv** CS papers (AI, ML, CV, NLP, DBâ€¦) stored in a **ChromaDB** vector DB |
| **Deep NLP toolkit** | Summarisation (BART-CNN), extractive QA (RoBERTa-SQuAD2), keyword & entity extraction, complexity analysis |
| **Beautiful Streamlit UI** | Chat, advanced paper search, visual dashboards (Plotly, NetworkX, word-clouds) |
| **100 % free & open source** | No paid APIsâ€”everything runs on your machine |
| **Perfect for GATE / research prep** | Ask anything, drill down with follow-ups, export data & chat history |

---

## ğŸ—‚ï¸ Repository Structure

```

cs_expert_chatbot/
â”œâ”€â”€ app.py                  \# Streamlit front-end (main entry point)
â”œâ”€â”€ data_processor.py       \# arXiv downloader + embedding creator
â”œâ”€â”€ llm_engine.py           \# Llama 3 + RAG + query-type router
â”œâ”€â”€ rag_system.py           \# ChromaDB vector store helper
â”œâ”€â”€ nlp_pipeline.py         \# Advanced NLP utilities
â”œâ”€â”€ concept_visualizer.py   \# Plotly / NetworkX visual tools
â”œâ”€â”€ knowledge_base.py       \# Core CS concept dictionary
â”œâ”€â”€ requirements.txt        \# Python deps (only free/open-source)
â”œâ”€â”€ config.yaml             \# All tunables in one place
â”œâ”€â”€ setup.py                \# One-shot installer (optional)
â””â”€â”€ README.md               \# You are here

```

---

## âš¡ Quick Start

### Prerequisites
* Python â‰¥ 3.9  
* ~8 GB RAM (16 GB recommended)  
* **Ollama** (for the Llama 3 model)  
```


# macOS / Linux

curl -fsSL https://ollama.ai/install.sh | sh

# Windows: install from https://ollama.ai/download

```

### 1. Clone & install
```

git clone https://github.com/your-org/cs_expert_chatbot.git
cd cs_expert_chatbot
python -m venv .venv \&\& source .venv/bin/activate    \# Windows: .venv\Scripts\activate
python setup.py          \# installs deps, spaCy model, pulls Llama 3, builds folders

```

*(No `setup.py`? â†’ `pip install -r requirements.txt && python -m spacy download en_core_web_sm`)*

### 2. Launch
```

streamlit run app.py

```
Open `http://localhost:8501` in your browser. First run will:

1. Grab ~1 000 latest CS papers from arXiv  
2. Generate sentence-BERT embeddings  
3. Build / populate the ChromaDB vector store  

Subsequent runs load from cache (fast ğŸš€).

---

## âœ¨ What Can I Ask?

| Example                                        | What the bot does                                                                               |
|------------------------------------------------|-------------------------------------------------------------------------------------------------|
| *â€œWhat is a transformer?â€*                     | Gives a didactic definition + diagrams + citations                                              |
| *â€œLatest advances in diffusion models (2024)?â€*| Classifies as **recent**, pulls recent arXiv papers, synthesises SOTA trends                    |
| *â€œSummarise this paper on neural architecture searchâ€* | Summarises abstract, lists methods/results, shows PDF link                                      |
| *Follow-up:* â€œCompare it with earlier NAS methodsâ€ | Keeps context, contrasts techniques, links additional papers                                    |

---

## ğŸ—ï¸ Architecture Overview 

```

User â”€â”¬â”€â–º Streamlit UI (app.py)
â”‚
â”œâ”€â–º  LLM Engine (llm_engine.py)
â”‚      â”œâ”€ Local Llama3 via Ollama
â”‚      â”œâ”€ Query classifier (fundamental / advanced / recent / paper-specific)
â”‚      â””â”€ RAG wrapper â†’ ChromaDB vector store
â”‚
â”œâ”€â–º  RAG System (rag_system.py)  â†”  ChromaDB (DuckDB+Parquet)
â”‚
â”œâ”€â–º  NLP Pipeline (nlp_pipeline.py)
â”‚      â”œâ”€ Summarisation (BART)
â”‚      â”œâ”€ QA (RoBERTa SQuAD2)
â”‚      â””â”€ Keyword / entity / complexity
â”‚
â””â”€â–º  Visualizer (concept_visualizer.py) â†’ Plotly dashboards

```

---

## ğŸ”§ Configuration

All knobs live in `config.yaml`.

```

llm:
model_name: "llama3"
temperature: 0.7
data:
max_papers: 1000
categories: ["cs.AI","cs.LG","cs.CL"]
rag:
top_k_papers: 5
similarity_threshold: 0.3

```

Change & restartâ€“â€“everything is auto-reloaded thanks to Streamlit caching.

---

## ğŸ› ï¸ Troubleshooting

| Problem | Fix |
|---------|-----|
| **`torch.classes` warning** in console | Harmless. Suppress by adding:<br>`warnings.filterwarnings("ignore", message=".*torch.classes.*")` |
| Stuck on â€œCreating embeddingsâ€ | Large paper set + CPU-only â†’ be patient (5-10 min). Reduce `data.max_papers` to 500. |
| Chat says â€œModel unavailableâ€ | Ensure Ollama is running (`ollama list`) and you have pulled `ollama pull llama3`. |
| â€œlist indices must be integersâ€ on start | Delete corrupt caches:<br>`del arxiv_papers.json enhanced_embeddings.pkl` (Windows) or `rm` on Linux. |

---

## ğŸ§© Extending

| Want toâ€¦ | Where to hack |
|----------|---------------|
| Add a new LLM | `llm_engine.py` â†’ `setup_llm()` |
| Plug other vector DB | `rag_system.py` |
| Add extra charts | `concept_visualizer.py` |
| Fine-tune query routing | `llm_engine.classify_query()` |

âœ… Pull requests & feature ideas are welcome!

---

## ğŸ“ License

This project is released under the **MIT License**.  
All models and datasets used are open-source; please respect their individual licenses.

---

## ğŸ™ Acknowledgements

* **Meta AI** â€“ Llama 3  
* **arXiv.org** â€“ Open scientific papers  
* **Ollama, ChromaDB, Streamlit** â€“ Amazing open-source tooling  
* The broader open-source community â€“ You make research accessible!  

---

### Happy learning & researching ğŸš€


